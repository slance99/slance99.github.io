{
  "hash": "1efa96e2a0139264c4240e05e53c01ba",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Text Analysis of Jurassic Park\"\ndescription: \"Word frequency and sentiment analysis of the text from the book Jurassic Park by Michael Crichton\"\nauthor:\n  - name: Sam Lance\n    affiliation: Master of Environmental Science and Management at the The Bren School (UCSB), Advanced Data Analysis (ESM 244)\ndate: 18 March, 2025\ncategories: [Data Analysis, R] # self-defined categories\nimage: dino_cover.jpg\nformat:\n  html:\n    code-fold: true\n    toc: false\n    number-sections: true\n    embed-resources: true\n    theme: Lux\neditor: visual\nexecute:\n  echo: true\n  message: false\n  warning: false\ndraft: false \n---\n\n\n\n<figure style=\"text-align: center;\">\n\n<img src=\"sam_jp.jpg\" alt=\"Author Photoshopped Sitting on Jurassic Park Logo of Dinosaur in Circle\" width=\"600px\"/>\n\n<figcaption>Sam Sitting on Jurassic Park Logo, Photoshop Courtesy of Sam Lance</figcaption>\n\n</figure>\n\n## Data Description and Citation\n\nThe data used in this analysis is the text of the book \"Jurassic Park\" by Michael Crichton. The data was obtained from the website Readers Library (https://readerslibrary.org/wp-content/uploads/Jurassic-Park.pdf). The citation for the book is as follows:\n\nCrichton, Michael. Jurassic Park. New York: Alfred A. Knopf, 1990.\n\n## Analysis\n\nThis analysis will focus on the text of the book Jurassic Park by Michael Crichton. The book begins by following the travels of a group of scientists to Isla Nublar, and over time shifts into an action novel/ mediation on the ethics of science. I noticed this stark change in tone when reading the book, which made me curious about whether this trend would appear through text and sentiment analysis.\n\nOne quick note on the structure of this analysis is that while the book has traditional chapters, it is also broken up into six different fractal iterations. Each iteration shows a picture of a fractal, a repeating geometric pattern, and a description of how patterns begin to emerge as more of the pattern is seen. These special markers appear at pivotal moments of the book, and will be used in place of chapters to measure how sentiments change further through the book.\n\n<figure style=\"text-align: center;\">\n\n<img src=\"fractal.jpg\" alt=\"Fractal from Jurassic Park Chapter 1\" height=\"350px\"/>\n\n<figcaption>Example Fractal Image from the First Chapter of the Book, Courtesy of @TheRealDoctorT on X</figcaption>\n\n</figure>\n\n## Steps of Analysis\n\nThe steps taken in this analysis are as follows:\n\n1.  Load Data\n2.  Wrangle Data\n    1.  Load in PDF\n    2.  Convert into Dataframe\n    3.  Convert Iterations into Chapters - iterations best way to divide not actual chapters\n    4.  Separate Out Each Word\n    5.  Remove Other Words - names, numbers, etc.\n3.  Create Column Chart\n4.  Create Word Cloud\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(here)\nlibrary(janitor)\nlibrary(tsibble)\nlibrary(feasts)\nlibrary(fable)\nlibrary(tidytext)\nlibrary(pdftools)\nlibrary(ggwordcloud)\nlibrary(textdata)\n```\n:::\n\n\n\n## Loading PDF Document\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\njp_text <- pdftools::pdf_text(here(\"posts\",\"2025-03-19-jp-244\", \"data\", \"jurassic_park.pdf\"))\n```\n:::\n\n\n\n## Wrangling and Turning into Dataframe\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#######################################################\n#CONVERT INTO A DATAFRAME \n#######################################################\n\njp_lines <- data.frame(jp_text) |>\n  mutate(page= 1:n()) |> #create a column for each page \n  mutate(text_full = str_split(jp_text, pattern= '\\\\n')) |> #new vector within each column, each /n keeps as its own unique element within the vector itself, need // is telling r to look for \\n exactly as written\n  unnest(text_full) |> #extract each element of the vector as a row in the dataframe, unique observation for each line \n  mutate(text_full = str_trim(text_full))  #remove any leading or trailing white space\n\n#######################################################\n#GET CHAPTER NAMES\n#######################################################\n\njp_chapts <- jp_lines |> \n  slice(-(1:443)) |> #gets rid of preface + junk, find line by looking at the actual data \n  mutate(iteration = ifelse(str_detect(text_full, regex(\"Iteration\", ignore_case = FALSE)), text_full, NA)) |> #find where says chapter, if it does, put the chapter number in the new column, if not, put NA\n  fill(iteration, .direction = 'down') |> #fill in the nas with chapter from above it \n  separate(col = iteration, into = c(\"num\", \"it\"), sep = \" \")  |>#seperate out the word chapter and the number \n  mutate(num_numeric = case_when(\n    num == \"First\" ~ 1,\n    num == \"Second\" ~ 2,\n    num == \"Third\" ~ 3,\n    num == \"Fourth\" ~ 4,\n    num == \"Fifth\" ~ 5,\n    num == \"Sixth\" ~ 6,\n    num == \"Seventh\" ~ 7,\n    TRUE ~ NA_real_  # Any other values that don't match will be assigned NA\n  )) |>\n  drop_na()\n\n#######################################################\n#SEPERATE OUT EACH WORD\n#######################################################\njp_words <- jp_chapts |> \n  unnest_tokens(word, text_full) |> #take info from text_full and put into column called word\n  select(-jp_text) #taking out the column of the actual hobbit text \n\n#######################################################\n#GET RID OF STOP WORDS + NUMBERS + NAMES \n#######################################################\njp_wordcount <- jp_words |> \n  count(num_numeric, word) #count the number of times each word appears in each iteration\n\njp_words_clean <- jp_wordcount |> \n  anti_join(stop_words, by = 'word') |>#take out all stop words by the column word \n  filter(!str_detect(word, regex(\"[0-9]\", ignore_case = FALSE))) |> #take out all numbers\n  filter(!(word %in% c(\"grant\", \"gennaro\", \"hammond\", \"tim\", \"lex\", \"wu\", \"muldoon\", \"malcolm\", \"arnold\", \"regis\", \"harding\", \"nedry\", \"ed\", \"dodgson\", \"john\", \"alan\", \"ellie\", \"murphy\", \"satler\", \"dr.\", \"henry\", \"robert\", \"bob\", \"morris\", \"manuel\", \"dr\", \"bowman\", \"tina\", \"guitierrez\", \"ellen\", \"mike\", \"it’s\", \"don’t\", \"that’s\"))) #take out all names\n```\n:::\n\n\n\n::: panel-tabset\n## Creating Column Graph of Top Words\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntop_5 <- jp_words_clean %>% \n  group_by(num_numeric) %>% \n  arrange(-n) %>% \n  slice(1:5) %>%\n  ungroup() \n\n# Make the plot with reordered bars within each facet\njp_column <- top_5 %>%\n  ggplot(aes(y = word, x = n)) +  # Reorder 'word' by 'n' on the y-axis\n  geom_col(fill = \"#520101\") +\n  theme_minimal() + \n  labs(title = \"Top 5 Words in Each Iteration\", x = \"Word Count\", y = NULL) +\n  facet_wrap(~num_numeric, scales = \"free\") +  # Facet wrap by num_numeric\n  theme(axis.text.x = element_text(hjust = 1))  # Optional: Rotate x labels\n\n# Display the plot\njp_column\n```\n\n::: {.cell-output-display}\n![](a4_task_2_lance_sam_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n-   The words used closely mirror the major problems faced by the characters throughout the book, especially the transition between tyrannosaur to raptor to nest\n\n-   If character names were not eliminated from the analysis, the top 5 words for every category would just be character names\n\n## Wordcloud\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntop_100 <- jp_words_clean %>% \n  arrange(-n) %>% \n  slice(1:100)\n\ncloud <- ggplot(data = top_100, aes(label = word)) +\n  geom_text_wordcloud(aes(color = n, size = n), shape = \"diamond\") +\n  scale_size_area(max_size = 6) +\n  scale_color_gradientn(colors = c(\"#520101\",\"#a60000\",\"#ff0000\")) +\n  theme_minimal()\ncloud\n```\n\n::: {.cell-output-display}\n![](a4_task_2_lance_sam_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n-   Similar results to the column graph, but shows how frequently the word animals is used throughout the text, with dinosaurs as a close second\n\n-   The word head also appears frequently throughout the book, likely referring to animals moving their heads to look at the characters or peeking around corners\n\n## Sentiment Analysis\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#LOAD IN + LINK THE BING LEXICON\nbing_lex <- get_sentiments(lexicon = \"bing\")\n\njp_bing <- jp_words_clean %>% \n  inner_join(bing_lex, by = 'word') \n\n#CREATE LOG RATIO FOR THE ENTIRE BOOK\nbing_log_ratio_book <- jp_bing %>% \n  summarize(n_pos = sum(sentiment == 'positive'),\n            n_neg = sum(sentiment == 'negative'),\n            log_ratio = log(n_pos / n_neg))\n\n#CREATE THE LOG RATIO FOR EACH CHAPTER \nbing_log_ratio_ch <- jp_bing %>% \n  group_by(num_numeric) %>% \n  summarize(n_pos = sum(sentiment == 'positive'),\n            n_neg = sum(sentiment == 'negative'),\n            log_ratio = log(n_pos / n_neg)) %>%\n  mutate(log_ratio_adjust = log_ratio - bing_log_ratio_book$log_ratio) %>%\n  mutate(pos_neg = ifelse(log_ratio_adjust > 0, 'pos', 'neg'))\n\n#CREATE PLOT \nggplot(data = bing_log_ratio_ch, \n       aes(x = log_ratio_adjust,\n           y = fct_rev(factor(num_numeric)),\n           fill = pos_neg)) +\n           # y = fct_rev(as.factor(chapter)))) +\n  geom_col() +\n  labs(x = 'Adjusted Log (Positive/Negative)',\n       y = 'Iteration (Section) Number',\n       title = \"Sentiment Analyis of Iterations in Jurassic Park\") +\n  scale_fill_manual(values = c('pos' = 'darkgreen', 'neg' = 'darkred')) +\n  theme_minimal() +\n  theme(legend.position = 'none')\n```\n\n::: {.cell-output-display}\n![](a4_task_2_lance_sam_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n-   As was expected, the second half of the book is significantly more negative then the first half\n\n-   Looking at the text analysis, the tyrannosaur appears for the first time in iteration 4, which could be the driving factor in the tone of the book shifting\n:::\n",
    "supporting": [
      "a4_task_2_lance_sam_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}